{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from vision_base.utils.builder import build\n",
    "from vision_base.data.datasets.dataset_utils import collate_fn\n",
    "from vision_base.utils.utils import cfg_from_file\n",
    "\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "#cfg = cfg_from_file(\"../configs/kitti360_gtpose_config.py\")\n",
    "#cfg = cfg_from_file(\"../configs/distill_monodepth2_gt_poseconfig.py\")\n",
    "#cfg = cfg_from_file(\"../configs/nusc_monodepth2wpose_config.py\")\n",
    "#cfg = cfg_from_file(\"../configs/monodepth2_gtpose_uncertainty_config.py\")\n",
    "cfg = cfg_from_file(\"../configs/kitti360_fisheye.py\")\n",
    "is_test_train = True\n",
    "\n",
    "#checkpoint_name = \"../workdirs/MonoDepth2_pose/checkpoint/MonoDepthWPose_ss11.pth\"\n",
    "#checkpoint_name = \"../workdirs/Distillation_gtpose/checkpoint/DistillWPoseMeta_trained_ss8.pth\"\n",
    "#checkpoint_name = \"../workdirs/MonoDepth2Nusc/checkpoint/MonoDepthWPose_ss11_threecam.pth\"\n",
    "checkpoint_name = \"../workdirs/KITTI360_fisheye/checkpoint/lib.networks.models.meta_archs.monodepth2_model.MonoDepthWPose_4.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "split_to_test='validation'\n",
    "cfg.train_dataset.augmentation = cfg.val_dataset.augmentation\n",
    "is_test_train = split_to_test == 'training'\n",
    "if split_to_test == 'training':\n",
    "    dataset = build(**cfg.train_dataset)\n",
    "elif split_to_test == 'test':\n",
    "    dataset = build(**cfg.test_dataset)\n",
    "else:\n",
    "    dataset = build(**cfg.val_dataset)\n",
    "\n",
    "\n",
    "meta_arch = build(**cfg.meta_arch)\n",
    "meta_arch = meta_arch.cuda()\n",
    "\n",
    "weight_path = checkpoint_name\n",
    "state_dict = torch.load(weight_path, map_location='cuda:{}'.format(cfg.trainer.gpu))\n",
    "\n",
    "meta_arch.load_state_dict(state_dict['model_state_dict'])\n",
    "meta_arch.eval();\n",
    "\n",
    "test_hook = build(**cfg.trainer.evaluate_hook.test_run_hook_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(image):\n",
    "    new_image = np.clip((image * cfg.data.augmentation.rgb_std +  cfg.data.augmentation.rgb_mean) * 255, 0, 255)\n",
    "    new_image = np.array(new_image, dtype=np.uint8)\n",
    "    return new_image\n",
    "\n",
    "from numba import jit\n",
    "@jit(cache=False, nopython=True)\n",
    "def ToColorDepth(depth_image:np.ndarray)->np.ndarray: #[H, W] -> [H, W, 3]\n",
    "    H, W = depth_image.shape\n",
    "    max_depth = float(np.max(depth_image))\n",
    "    cmap = np.array([\n",
    "        [0,0,0,114],[0,0,1,185],[1,0,0,114],[1,0,1,174], \n",
    "        [0,1,0,114],[0,1,1,185],[1,1,0,114],[1,1,1,0]\n",
    "    ])\n",
    "    _sum  = 0\n",
    "    for i in range(8):\n",
    "        _sum += cmap[i, 3]\n",
    "    \n",
    "    weights = np.zeros(8)\n",
    "    cumsum = np.zeros(8)\n",
    "    for i in range(7):\n",
    "        weights[i] = _sum / cmap[i, 3]\n",
    "        cumsum[i+1] = cumsum[i] + cmap[i, 3] / _sum\n",
    "    \n",
    "    image = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            val = depth_image[i, j] / max_depth\n",
    "            for k in range(7):\n",
    "                if val <= cumsum[k + 1]:\n",
    "                    break\n",
    "            w = 1.0- (val - cumsum[k]) * weights[k]\n",
    "            r = int( (w * cmap[k, 0] + (1 - w) * cmap[k+1, 0]) * 255 )\n",
    "            g = int( (w * cmap[k, 1] + (1 - w) * cmap[k+1, 1]) * 255 )\n",
    "            b = int( (w * cmap[k, 2] + (1 - w) * cmap[k+1, 2]) * 255 )\n",
    "            image[i, j] = np.array([r,g,b])\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_once(index):\n",
    "    data = dataset[index]\n",
    "    collated_data = collate_fn([data])\n",
    "    image = collated_data[('image', 0)]\n",
    "    rgb_image = denorm(image[0].cpu().numpy().transpose([1, 2, 0]))\n",
    "    with torch.no_grad():\n",
    "        output_dict = test_hook(collated_data, meta_arch)\n",
    "        depth = output_dict[\"depth\"][0, 0]\n",
    "        print(depth.max(), depth.min())\n",
    "        depth_uint16 = (depth * 256).cpu().numpy().astype(np.uint16)\n",
    "        color_depth = ToColorDepth(depth_uint16)\n",
    "       \n",
    "    plt.subplot(2, 2, 1)\n",
    "    \n",
    "    plt.imshow(np.clip(rgb_image, 0, 255)[:])\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow( 1 / (depth_uint16 / 256)[:], cmap='magma', vmin=1.0/(70), vmax= 1 / max(depth_uint16.min()/256, 2.0) )\n",
    "    \n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    color_depth = ToColorDepth(depth_uint16)\n",
    "    plt.imshow(depth_uint16 / 256)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    alpha = 0.3\n",
    "    masked = (alpha * color_depth + (1 - alpha) * rgb_image).astype(np.uint8)\n",
    "    plt.imshow(masked)\n",
    "\n",
    "    plt.show()\n",
    "    return np.clip(rgb_image, 0, 255), color_depth, depth_uint16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "index = np.random.randint(0, len(dataset))\n",
    "fig = plt.figure(figsize=(16, 20))\n",
    "rgb_image, color_depth, depth_uint16  = compute_once(index);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

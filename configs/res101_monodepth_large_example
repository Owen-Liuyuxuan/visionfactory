from easydict import EasyDict as edict
import os
import numpy as np

cfg = edict()



## path
def build_path():
    path = edict()
    path.kitti_path = "/data/kitti_raw"
    path.kitti360_path = "/data/KITTI-360"
    path.nuscenes_dir = "/data/nuscene"
    path.base_path = "/home/yliuhb/vision_collection/src/learning/FSNet"
    path.project_path = "/home/yliuhb/vision_collection/src/learning/FSNet/workdirs"
    if not os.path.isdir(path.project_path):
        os.mkdir(path.project_path)
    path.project_path = os.path.join(path.project_path, 'k_k360_nusc_res101WPose')
    if not os.path.isdir(path.project_path):
        os.mkdir(path.project_path)

    path.log_path = os.path.join(path.project_path, "log")
    if not os.path.isdir(path.log_path):
        os.mkdir(path.log_path)

    path.checkpoint_path = os.path.join(path.project_path, "checkpoint")
    if not os.path.isdir(path.checkpoint_path):
        os.mkdir(path.checkpoint_path)

    path.preprocessed_path = os.path.join(path.project_path, "output")
    if not os.path.isdir(path.preprocessed_path):
        os.mkdir(path.preprocessed_path)

    path.train_imdb_path = os.path.join(path.preprocessed_path, "training")
    if not os.path.isdir(path.train_imdb_path):
        os.mkdir(path.train_imdb_path)

    path.val_imdb_path = os.path.join(path.preprocessed_path, "validation")
    if not os.path.isdir(path.val_imdb_path):
        os.mkdir(path.val_imdb_path)
    return path

cfg.path = build_path()

## trainer
trainer = edict(
    gpu = 0,
    max_epochs = 10,
    disp_iter = 50,
    save_iter = 5,
    test_iter = 10,
    training_hook = edict(
        name='vision_base.pipeline_hooks.train_val_hooks.base_training_hooks.BaseTrainingHook',
        clip_gradients=1.0,
    ),
    evaluate_hook = edict(
        name="monodepth.pipeline_hooks.evaluation_hooks.base_evaluation_hooks.KittiEvaluationHook",
        test_run_hook_cfg=edict(name='vision_base.pipeline_hooks.train_val_hooks.base_validation_hooks.BaseValidationHook'),
        result_write_cfg=edict(name='monodepth.data.data_writer.kitti_depth_writer.KittiDepthWriter',
                                result_path=os.path.join(cfg.path.val_imdb_path, 'data'),
                ),
        preprocessed_path=cfg.path.preprocessed_path,
        dataset_eval_cfg=edict(
            name='monodepth.evaluation.kitti_unsupervised_eval.KittiEigenEvaluator',
            data_path=cfg.path.kitti_path,
            split_file=os.path.join(cfg.path.base_path, 'meta_data', 'eigen', 'test_files.txt'),
            gt_saved_file=os.path.join(cfg.path.base_path, 'meta_data', 'eigen', 'gt_depths.npz'),
       ),
    )
    #evaluate_hook = edict(
    #    name="monodepth.pipeline_hooks.evaluation_hooks.base_evaluation_hooks.KittiEvaluationHook",
    #    test_run_hook_cfg=edict(name='vision_base.pipeline_hooks.train_val_hooks.base_validation_hooks.BaseValidationHook'),
    #    preprocessed_path=cfg.path.preprocessed_path,
   #     dataset_eval_cfg=edict(
   #         name='monodepth.evaluation.kitti_unsupervised_eval.Kitti360Evaluator',
   #         data_path=cfg.path.kitti360_path,
   #         split_file=os.path.join(cfg.path.base_path, 'meta_data', 'kitti360_trainsub', 'kitti360_val.txt'),
   #         gt_saved_file=os.path.join(cfg.path.base_path, 'meta_data', 'kitti360_trainsub', 'gt_depth.npz'),
   #     ),
   # )
    #evaluate_hook = edict(
    #    name="monodepth.pipeline_hooks.evaluation_hooks.base_evaluation_hooks.FastEvaluationHook",
    #    test_run_hook_cfg=edict(name='vision_base.pipeline_hooks.train_val_hooks.base_validation_hooks.BaseValidationHook'),
    #    result_write_cfg=edict(name='monodepth.data.data_writer.nuscene_depth_writer.NusceneDepthWriter',
    #                            result_path=os.path.join(cfg.path.val_imdb_path, 'data'), 
    #                            #split_file=os.path.join(cfg.path.base_path, 'meta_data', 'nusc_trainsub', 'nusc_val.txt'),
    #                            #channels=['CAM_BACK', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_RIGHT', 'CAM_BACK_LEFT', 'CAM_FRONT_LEFT']
    #            ),
    #    preprocessed_path=cfg.path.preprocessed_path,
    #    dataset_eval_cfg=edict(
    #        name='monodepth.evaluation.nuscenes_unsupervised_eval.NuscenesEvaluator',
    #        data_path=cfg.path.nuscenes_dir,
    #        split_file=os.path.join(cfg.path.base_path, 'meta_data', 'nusc_trainsub', 'nusc_val.txt'),
    #        gt_saved_dir=os.path.join(cfg.path.base_path, 'meta_data', 'nusc_trainsub', 'samples_depth_gt'),
    #    ),
    #)
)
cfg.trainer = trainer

## optimizer
optimizer = edict(
    name = 'adam',
    lr        = 1e-4,
    weight_decay = 0,
)
cfg.optimizer = optimizer
## scheduler
scheduler = edict(
    name = 'StepLR',
    step_size = 4
)
cfg.scheduler = scheduler

data = edict(
    batch_size = 4,
    num_workers = 1,
    # rgb_shape = (192, 640, 3),
    #rgb_shape = (256, 832, 3),
    #rgb_shape = (320, 1088, 3),
    rgb_shape = (384, 1280, 3),
    frame_idxs  = [0, 1, -1],
)

train_dataset = edict(
    name = "vision_base.data.datasets.dataset_utils.ConcatDataset",
    frame_idxs = data.frame_idxs,
    is_motion_mask = False,
    is_precompute_flow = False,
    is_filter_static = True,
    cfg_list = [
        edict(
            name = "monodepth.data.datasets.mono_dataset.KittiDepthMonoDataset",
            raw_path = cfg.path.kitti_path,
            split_file = os.path.join(cfg.path.base_path, 'meta_data', 'eigen_zhou', 'train_files.txt'),
        ),
        edict(
           name = "monodepth.data.datasets.kitti360_dataset.KITTI360MonoDataset",
           data_path = cfg.path.kitti360_path,
           split_file = os.path.join(cfg.path.base_path, 'meta_data', 'kitti360_trainsub', 'kitti360_train.txt'),
        ),
        edict(
           name = "monodepth.data.datasets.nuscene_dataset.NusceneJsonDataset",
           json_path = os.path.join(cfg.path.base_path, 'meta_data', 'nusc_trainsub', 'json_nusc_front_train.json'),
        ),
        edict(
           name = "monodepth.data.datasets.nuscene_dataset.NusceneJsonDataset",
           json_path = os.path.join(cfg.path.base_path, 'meta_data', 'nusc_trainsub', 'json_nusc_sweep_train.json'),
        ),
    ],
)

val_dataset = edict(
    name = "monodepth.data.datasets.mono_dataset.KittiDepthMonoEigenTestDataset",
    raw_path = cfg.path.kitti_path,
    split_file = os.path.join(cfg.path.base_path, 'meta_data', 'eigen', 'test_files.txt'),
)

# val_dataset = edict(
#   name = "monodepth.data.datasets.kitti360_dataset.KITTI360MonoDataset",
#   raw_path = cfg.path.kitti360_path,
#   split_file = os.path.join(cfg.path.base_path, 'meta_data', 'kitti360_trainsub', 'kitti360_val.txt'),
#   is_filter_static = False,
#   use_right_image=False,
#   frame_ids=[0]
# )

# val_dataset = edict(
#    name = "monodepth.data.datasets.nuscene_dataset.NusceneJsonDataset",
#    json_path = os.path.join(cfg.path.base_path, 'meta_data', 'nusc_trainsub', 'json_nusc_all_val.json'),
#    image_keys=['frame0'],
#    frame_ids=[0]
# )

### Build Augmentation
resize_image_keys=[('image', idx) for idx in data.frame_idxs] + [('original_image', idx) for idx in data.frame_idxs]
color_augmented_image_keys = [('image', idx) for idx in data.frame_idxs]
pose_axis_pairs = [
    (("relative_pose", idx), 0) for idx in data.frame_idxs[1:]
]
data.augmentation = edict(
    rgb_mean = np.array([0.485, 0.456, 0.406]),
    rgb_std  = np.array([0.229, 0.224, 0.225]),
    cropSize = (data.rgb_shape[0], data.rgb_shape[1]),
    #crop_top = 100,
    key_mappings=edict(
        image_keys=resize_image_keys,
        calib_keys=['P2'],
        gt_image_keys=['patched_mask'],
    )
)
train_dataset.augmentation = edict(
    name='vision_base.utils.builder.Sequential',
    cfg_list = [
        edict(name='vision_base.data.augmentations.augmentations.ConvertToFloat'),
        #edict(name='vision_base.data.augmentations.augmentations.RandomWarpAffine', output_w=data.augmentation.cropSize[1], output_h=data.augmentation.cropSize[0]),
        edict(name='vision_base.data.augmentations.augmentations.Resize', size=data.augmentation.cropSize, preserve_aspect_ratio=True, force_pad=True),
        edict(name="vision_base.utils.builder.Shuffle", 
              cfg_list=[
                    edict(name="vision_base.data.augmentations.augmentations.RandomBrightness", distort_prob=1.0),
                    edict(name="vision_base.data.augmentations.augmentations.RandomContrast", distort_prob=1.0, lower=0.6, upper=1.4),
                    edict(name="vision_base.utils.builder.Sequential",
                        cfg_list=[
                            edict(name="vision_base.data.augmentations.augmentations.ConvertColor", transform='HSV'),
                            edict(name="vision_base.data.augmentations.augmentations.RandomSaturation", distort_prob=1.0, lower=0.6, upper=1.4),
                            edict(name="vision_base.data.augmentations.augmentations.ConvertColor", current='HSV', transform='RGB'),
                        ] 
                    )
            ],
            image_keys=color_augmented_image_keys,
        ),
        edict(name='vision_base.data.augmentations.augmentations.RandomMirror', mirror_prob=0.5, pose_axis_pairs=pose_axis_pairs),
        edict(name='vision_base.data.augmentations.augmentations.Normalize', mean=data.augmentation.rgb_mean, stds=data.augmentation.rgb_std, image_keys=color_augmented_image_keys),
        edict(name='vision_base.data.augmentations.augmentations.Normalize', mean=np.array([0, 0, 0]), stds=np.array([1, 1, 1]), image_keys=[('original_image', idx) for idx in data.frame_idxs]),
        edict(name='vision_base.data.augmentations.augmentations.ConvertToTensor'),
        
    ],
    **data.augmentation.key_mappings # common keywords
)

val_dataset.augmentation = edict(
    name='vision_base.utils.builder.Sequential',
    cfg_list=[
        edict(name='vision_base.data.augmentations.augmentations.ConvertToFloat'),
        edict(name='vision_base.data.augmentations.augmentations.Resize', size=data.augmentation.cropSize, preserve_aspect_ratio=True, force_pad=True),
        edict(name='vision_base.data.augmentations.augmentations.Normalize', mean=data.augmentation.rgb_mean, stds=data.augmentation.rgb_std),
        edict(name='vision_base.data.augmentations.augmentations.ConvertToTensor'),
    ],
    image_keys=[('image', 0)], 
    calib_keys=['P2'],
    #gt_image_keys=['patched_mask'],
)
    
cfg.data = data
cfg.train_dataset = train_dataset
cfg.val_dataset = val_dataset

## networks
meta_arch = edict(
    name='monodepth.networks.models.meta_archs.monodepth2_model.MonoDepthWPose',

    depth_backbone_cfg = edict(
        name='vision_base.networks.models.backbone.resnet.resnet',
        depth=101,
        pretrained=True,
        frozen_stages=-1,
        num_stages=4,
        out_indices=(-1, 0, 1, 2, 3),
        norm_eval=False,
        dilations=(1, 1, 1, 1),
    ),

    head_cfg = edict(
        name='monodepth.networks.models.heads.monodepth2_decoder.MonoDepth2Decoder',
        scales=[0, 1, 2, 3],
        height=data.rgb_shape[0],
        width=data.rgb_shape[1],
        min_depth=0.5,
        max_depth=100.0,
        overlapped_mask=False,
        is_log_image=False,
        depth_decoder_cfg=edict(
            name='monodepth.networks.models.heads.depth_encoder.MultiChannelDepthDecoder', #MultiChannelScaleDepthDecoder',
            #num_ch_enc=np.array([64, 64, 128, 256, 512]),
            num_ch_enc=np.array([64, 256, 512, 1024, 2048]),
            num_output_channels=64,
            use_skips=True,
            scales=[0, 1, 2, 3],
            min_depth=0.5,
            max_depth=100,
            base_fx=738 #[kitti_raw at 256] == 
        ),
    ),

    train_cfg = edict(
        frame_ids=[0, 1, -1],
    ),

    test_cfg = edict(

    ),
)



cfg.meta_arch = meta_arch